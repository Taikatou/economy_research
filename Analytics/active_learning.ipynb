{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "6eebf992",
      "metadata": {
        "id": "6eebf992"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Concatenate\n",
        "from keras import Model\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "0513b960",
      "metadata": {
        "id": "0513b960"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "88129aa5",
      "metadata": {
        "id": "88129aa5"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "  x = Input(shape=(60,), name=\"Game Play Data\")\n",
        "  y = Input(shape=(3,), name=\"Selected Character\")\n",
        "  g = Concatenate()([x, y])\n",
        "\n",
        "  g = Dense(500, activation='relu', input_dim=8)(g)\n",
        "  g = Dense(100, activation='relu')(g)\n",
        "  g = Dense(50, activation='relu')(g)\n",
        "  g = Dense(3, activation='softmax')(g)\n",
        "  model = Model(inputs=[x, y], outputs=g)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "08dbd3c0",
      "metadata": {
        "id": "08dbd3c0"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "8ada1700",
      "metadata": {
        "id": "8ada1700"
      },
      "outputs": [],
      "source": [
        "type_path = \"sample_data/test_data\"\n",
        "graph_data = { }\n",
        "game_play_data = { }\n",
        "hash_data = {}\n",
        "environments = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "82bdbec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bdbec6",
        "outputId": "e80de164-ab26-4f64-9403-94d173488f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]\n"
          ]
        }
      ],
      "source": [
        "level_cap = 5\n",
        "configuration_data = {}\n",
        "\n",
        "for filename in os.listdir(type_path):\n",
        "    file_path = os.path.join(type_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if \"level_selection\" in file_path:\n",
        "            if filename not in hash_data:\n",
        "                hash_data[filename] = []\n",
        "                environments[filename] = {}\n",
        "            for i in range(len(df)):\n",
        "                battle_environment = df.loc[i, 'BattleEnvironment']\n",
        "                battle_id = df.loc[i, 'ID']\n",
        "                if battle_environment not in environments:\n",
        "                    environments[filename][battle_environment] = [0, 0, 0, 0, 0]\n",
        "                if battle_id not in hash_data:\n",
        "                    level = df.loc[i, 'Level']\n",
        "                    environments[filename][battle_environment][level] = environments[filename][battle_environment][level] + 1\n",
        "                    hash_data[filename].append(battle_id)\n",
        "        elif \"level_configuration\" in filename:\n",
        "            for i in range(len(df)):\n",
        "              config = df.iloc[i].values.tolist()\n",
        "              print(config)\n",
        "              configuration_data[config[0]] = config[1:]\n",
        "              configuration_data[\"1\"] = config[1:]\n",
        "        else:\n",
        "            if filename not in game_play_data:\n",
        "                game_play_data[filename] = {\n",
        "                    \"Brawler\": {},\n",
        "                    \"Mage\": {},\n",
        "                    \"Swordsman\": {}\n",
        "                }\n",
        "                for key in game_play_data[filename]:\n",
        "                    game_play_data[filename][key] = [[], [], [], [], []]\n",
        "                graph_data[filename] = {}\n",
        "            adventurer_type = filename.split('_')[0]\n",
        "            for i in range(len(df)):\n",
        "                level = df.loc[i, 'Level']\n",
        "                max_steps = df.loc[i, 'MaxCount']\n",
        "                game_play_data[filename][adventurer_type][level-1].append(max_steps)\n",
        "            for key in game_play_data[filename]:\n",
        "                graph_data[filename][key] = [[], [], [], [], []]\n",
        "                for x in range(level_cap):\n",
        "                    if len(game_play_data[filename][key][x]) > 0:\n",
        "                        graph_data[filename][key][x] = mean(game_play_data[filename][key][x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "lGnGy2L7_ezr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGnGy2L7_ezr",
        "outputId": "42aaa5ce-ed38-4113-f671-8ab397407567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'02/08/2022 00:32:31': [0.2001211, 0.1932651, 0.2002864], '1': [0.2001211, 0.1932651, 0.2002864]}\n",
            "{'Brawler_1_02_08_2022_00_49.csv': {'Brawler': [[494, 1047, 1453, 9190, 11785, 12378, 14560, 20776, 20776, 378, 2840], [8829, 15548, 18060, 19795, 19863, 20417, 21139, 21762, 27576, 3054, 4660], [10534, 22181, 26814, 30327, 35099, 41009, 46389, 56164, 58369, 7926, 15190], [36723, 46389, 51863, 63547, 76626, 79677, 2328, 3964, 4257, 31775], [77339, 0, 18269, 0, 19783, 0]], 'Mage': [[], [], [], [], []], 'Swordsman': [[], [], [], [], []]}, 'Swordsman_1_02_08_2022_00_49.csv': {'Brawler': [[], [], [], [], []], 'Mage': [[], [], [], [], []], 'Swordsman': [[494, 1453, 2421, 6915, 9918, 11785, 13652, 2252, 9840, 4520], [1220, 1220, 4259, 12314, 13652, 14215, 15112, 21430, 21430, 28681, 5763, 480, 6785, 2015, 15286, 10027, 14770], [14560, 14972, 20417, 22201, 25807, 28365, 28831, 35099, 37490, 42255, 66534, 13000, 13281, 13161], [29660, 34003, 37490, 41312, 48011, 49147, 50170, 64643, 68249, 77007, 2705, 23530], [7502, 0, 22249, 0, 22623, 0, 24071, 0, 24443, 0, 28730, 0, 29792, 0, 31056, 0, 33928, 0]]}, 'Mage_1_02_08_2022_00_49.csv': {'Brawler': [[], [], [], [], []], 'Mage': [[1047, 2421, 4761, 9582, 12314, 12378, 13874, 14215, 15548, 29136, 5459, 3059, 1257, 5753, 9741], [4761, 9582, 13874, 19863, 20048, 21762, 27576, 32346, 34697, 39390, 1824, 3822, 8304, 6158, 15069, 3981, 9700], [14972, 22181, 29438, 34003, 36526, 38597, 42255, 46185, 51452, 59778, 7144, 6109, 14623, 9981, 20300, 26389], [26814, 37148, 49177, 61420, 70537, 72693, 72862, 73056, 76508, 80176, 29185], [75654, 0, 11982, 0, 13945, 0, 15614, 0, 17416, 0, 27051, 0, 28016, 0, 35498, 0]], 'Swordsman': [[], [], [], [], []]}}\n"
          ]
        }
      ],
      "source": [
        "print(configuration_data)\n",
        "print(game_play_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "25e73506",
      "metadata": {
        "id": "25e73506",
        "outputId": "7a3bd8fc-e4f9-459e-b9de-c7b9be3f15ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]\n"
          ]
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "VOE7PnkEA88C",
      "metadata": {
        "id": "VOE7PnkEA88C"
      },
      "outputs": [],
      "source": [
        "reviews = { \"02/08/2022 00:32:31\": [0, 0, 1], \"Test2\": [0, 0, 1] }\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = list(reviews.keys())\n",
        "labels = []\n",
        "labeled_config = []\n",
        "for key in y:\n",
        "  if key in configuration_data:\n",
        "    data = configuration_data[key]\n",
        "    labeled_config.append(data)\n",
        "    labels.append(reviews[key])\n",
        "\n",
        "unlabeled_data = []\n",
        "for key in configuration_data:\n",
        "  if key not in y:\n",
        "    data = configuration_data[key]\n",
        "    unlabeled_data.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "NB5FzG02EcO0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB5FzG02EcO0",
        "outputId": "e968b06a-18d0-4d2a-bb6d-c3b702208884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2001211, 0.1932651, 0.2002864]]\n",
            "02/08/2022 00:32:31\n",
            "[[0, 0, 1]]\n",
            "[[0.2001211, 0.1932651, 0.2002864]]\n"
          ]
        }
      ],
      "source": [
        "print(labeled_config)\n",
        "print(config[0])\n",
        "config = [config, config]\n",
        "print(labels)\n",
        "labels.append(labels[0])\n",
        "print(unlabeled_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(config)\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "l9ZCBJPL_vqq",
        "outputId": "46cb9b31-5fd0-4e57-b773-f78ff845239f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l9ZCBJPL_vqq",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864], ['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]]\n",
            "[[0, 0, 1], [0, 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "bN88s0qkDDAr",
      "metadata": {
        "id": "bN88s0qkDDAr"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels, val_data, val_labels = train_test_split(config, labels, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "HXgPXUNsGVg5",
      "metadata": {
        "id": "HXgPXUNsGVg5"
      },
      "outputs": [],
      "source": [
        "# Helper function for merging new history objects with older ones\n",
        "def append_history(losses, val_losses, accuracy, val_accuracy, history):\n",
        "    losses = losses + history.history[\"loss\"]\n",
        "    val_losses = val_losses + history.history[\"val_loss\"]\n",
        "    accuracy = accuracy + history.history[\"categorical_accuracy\"]\n",
        "    val_accuracy = val_accuracy + history.history[\"val_categorical_accuracy\"]\n",
        "    return losses, val_losses, accuracy, val_accuracy\n",
        "\n",
        "\n",
        "# Plotter function\n",
        "def plot_history(losses, val_losses, accuracies, val_accuracies):\n",
        "    plt.plot(losses)\n",
        "    plt.plot(val_losses)\n",
        "    plt.legend([\"train_loss\", \"val_loss\"])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(accuracies)\n",
        "    plt.plot(val_accuracies)\n",
        "    plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0wWG257MASxZ"
      },
      "id": "0wWG257MASxZ",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PrQGne8ovciZ",
      "metadata": {
        "id": "PrQGne8ovciZ"
      },
      "outputs": [],
      "source": [
        "def train_active_learning(\n",
        "    num_iterations=3,\n",
        "    sampling_size=5000):\n",
        "  # inspired from this https://keras.io/examples/nlp/active_learning_review_classification/\n",
        "  model = make_model()\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\n",
        "            keras.metrics.CategoricalAccuracy(),\n",
        "            keras.metrics.FalseNegatives(),\n",
        "            keras.metrics.FalsePositives(),\n",
        "        ],)\n",
        "  losses, val_losses, accuracies, val_accuracies = [], [], [], []\n",
        "\n",
        "  # Defining checkpoints.\n",
        "  # The checkpoint callback is reused throughout the training since it only saves the best overall model.\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "      \"AL_Model.h5\", save_best_only=True, verbose=1\n",
        "  )\n",
        "  # Here, patience is set to 4. This can be set higher if desired.\n",
        "  early_stopping = keras.callbacks.EarlyStopping(patience=4, verbose=1)\n",
        "\n",
        "  print(f\"Starting to train with {len(train_data)} samples\")\n",
        "  # Initial fit with a small subset of the training set\n",
        "  history = model.fit(\n",
        "      x=train_data,\n",
        "      y=train_labels,\n",
        "      epochs=20,\n",
        "      validation_data=(val_data, val_labels),\n",
        "      callbacks=[checkpoint, early_stopping],\n",
        "  )\n",
        "\n",
        "  # Appending history\n",
        "  losses, val_losses, accuracies, val_accuracies = append_history(\n",
        "      losses, val_losses, accuracies, val_accuracies, history\n",
        "  )\n",
        "\n",
        "  for iteration in range(num_iterations):\n",
        "      # Getting predictions from previously trained model\n",
        "      predictions = model.predict(train_data)\n",
        "\n",
        "      # Generating labels from the output probabilities\n",
        "      rounded = tf.where(tf.greater(predictions, 0.5), 1, 0)\n",
        "\n",
        "      # Evaluating the number of zeros and ones incorrrectly classified\n",
        "      scores = model.evaluate(train_data, train_labels, verbose=0)\n",
        "\n",
        "      print(\"-\" * 100)\n",
        "      print(\n",
        "          f\"Number of zeros incorrectly classified: {false_negatives}, Number of ones incorrectly classified: {false_positives}\"\n",
        "      )\n",
        "\n",
        "      # This technique of Active Learning demonstrates ratio based sampling where\n",
        "      # Number of ones/zeros to sample = Number of ones/zeros incorrectly classified / Total incorrectly classified\n",
        "      if false_negatives != 0 and false_positives != 0:\n",
        "          total = false_negatives + false_positives\n",
        "          sample_ratio_ones, sample_ratio_zeros = (\n",
        "              false_positives / total,\n",
        "              false_negatives / total,\n",
        "          )\n",
        "      # In the case where all samples are correctly predicted, we can sample both classes equally\n",
        "      else:\n",
        "          sample_ratio_ones, sample_ratio_zeros = 0.5, 0.5\n",
        "\n",
        "      print(\n",
        "          f\"Sample ratio for positives: {sample_ratio_ones}, Sample ratio for negatives:{sample_ratio_zeros}\"\n",
        "      )\n",
        "\n",
        "      # Sample the required number of ones and zeros\n",
        "      sampled_dataset = pool_negatives.take(\n",
        "          int(sample_ratio_zeros * sampling_size)\n",
        "      ).concatenate(pool_positives.take(int(sample_ratio_ones * sampling_size)))\n",
        "\n",
        "      # Skip the sampled data points to avoid repetition of sample\n",
        "      pool_negatives = pool_negatives.skip(int(sample_ratio_zeros * sampling_size))\n",
        "      pool_positives = pool_positives.skip(int(sample_ratio_ones * sampling_size))\n",
        "\n",
        "      # Concatenating the train_dataset with the sampled_dataset\n",
        "      train_dataset = train_dataset.concatenate(sampled_dataset).prefetch(\n",
        "          tf.data.AUTOTUNE\n",
        "      )\n",
        "\n",
        "      print(f\"Starting training with {len(train_dataset)} samples\")\n",
        "      print(\"-\" * 100)\n",
        "\n",
        "      # We recompile the model to reset the optimizer states and retrain the model\n",
        "      model.compile(\n",
        "          loss=\"categorical_crossentropy\",\n",
        "          optimizer=\"rmsprop\",\n",
        "          metrics=[\n",
        "              keras.metrics.CategoricalAccuracy(),\n",
        "              keras.metrics.FalseNegatives(),\n",
        "              keras.metrics.FalsePositives(),\n",
        "          ],\n",
        "      )\n",
        "      history = model.fit(\n",
        "          x=train_data,\n",
        "          y=train_labels,\n",
        "          validation_data=(val_data, val_labels),\n",
        "          epochs=20,\n",
        "          callbacks=[\n",
        "              checkpoint,\n",
        "              keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
        "          ],\n",
        "      )\n",
        "\n",
        "      # Appending the history\n",
        "      losses, val_losses, accuracies, val_accuracies = append_history(\n",
        "          losses, val_losses, accuracies, val_accuracies, history\n",
        "      )\n",
        "\n",
        "      # Loading the best model from this training loop\n",
        "      model = keras.models.load_model(\"AL_Model.h5\")\n",
        "\n",
        "      # Plotting the overall history and evaluating the final model\n",
        "  plot_history(losses, val_losses, accuracies, val_accuracies)\n",
        "  print(\"-\" * 100)\n",
        "  print(\n",
        "      \"Test set evaluation: \",\n",
        "      model.evaluate(test_dataset, verbose=0, return_dict=True),\n",
        "  )\n",
        "  print(\"-\" * 100)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_active_learning()"
      ],
      "metadata": {
        "id": "acUFA1ffAtq9",
        "outputId": "8c07d3b6-8b80-4c38-9deb-78f99d713c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "id": "acUFA1ffAtq9",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-0c8eda4fda98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_active_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train_active_learning() missing 4 required positional arguments: 'pool_negatives', 'pool_positives', 'val_dataset', and 'test_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e467ce8",
      "metadata": {
        "id": "4e467ce8"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "active_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}