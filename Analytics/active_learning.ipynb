{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6eebf992",
      "metadata": {
        "id": "6eebf992"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Concatenate\n",
        "from keras import Model\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0513b960",
      "metadata": {
        "id": "0513b960"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "08dbd3c0",
      "metadata": {
        "id": "08dbd3c0"
      },
      "outputs": [],
      "source": [
        "opt = keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8ada1700",
      "metadata": {
        "id": "8ada1700"
      },
      "outputs": [],
      "source": [
        "type_path = \"sample_data/test_data\"\n",
        "graph_data = { }\n",
        "game_play_data = { }\n",
        "hash_data = {}\n",
        "environments = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "82bdbec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bdbec6",
        "outputId": "77666129-76ce-471a-8d60-d2306e81fe94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]\n"
          ]
        }
      ],
      "source": [
        "level_cap = 5\n",
        "configuration_data = {}\n",
        "\n",
        "for filename in os.listdir(type_path):\n",
        "    file_path = os.path.join(type_path, filename)\n",
        "    if os.path.isfile(file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if \"level_selection\" in file_path:\n",
        "            if filename not in hash_data:\n",
        "                hash_data[filename] = []\n",
        "                environments[filename] = {}\n",
        "            for i in range(len(df)):\n",
        "                battle_environment = df.loc[i, 'BattleEnvironment']\n",
        "                battle_id = df.loc[i, 'ID']\n",
        "                if battle_environment not in environments:\n",
        "                    environments[filename][battle_environment] = [0, 0, 0, 0, 0]\n",
        "                if battle_id not in hash_data:\n",
        "                    level = df.loc[i, 'Level']\n",
        "                    environments[filename][battle_environment][level] = environments[filename][battle_environment][level] + 1\n",
        "                    hash_data[filename].append(battle_id)\n",
        "        elif \"level_configuration\" in filename:\n",
        "            for i in range(len(df)):\n",
        "              config = df.iloc[i].values.tolist()\n",
        "              print(config)\n",
        "              configuration_data[config[0]] = config[1:]\n",
        "              configuration_data[\"1\"] = config[1:]\n",
        "        else:\n",
        "            if filename not in game_play_data:\n",
        "                game_play_data[filename] = {\n",
        "                    \"Brawler\": {},\n",
        "                    \"Mage\": {},\n",
        "                    \"Swordsman\": {}\n",
        "                }\n",
        "                for key in game_play_data[filename]:\n",
        "                    game_play_data[filename][key] = [[], [], [], [], []]\n",
        "                graph_data[filename] = {}\n",
        "            adventurer_type = filename.split('_')[0]\n",
        "            for i in range(len(df)):\n",
        "                level = df.loc[i, 'Level']\n",
        "                max_steps = df.loc[i, 'MaxCount']\n",
        "                game_play_data[filename][adventurer_type][level-1].append(max_steps)\n",
        "            for key in game_play_data[filename]:\n",
        "                graph_data[filename][key] = [[], [], [], [], []]\n",
        "                for x in range(level_cap):\n",
        "                    if len(game_play_data[filename][key][x]) > 0:\n",
        "                        graph_data[filename][key][x] = mean(game_play_data[filename][key][x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "lGnGy2L7_ezr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGnGy2L7_ezr",
        "outputId": "4d0cadf8-f86d-494f-e6c0-8ff5c03a34a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'02/08/2022 00:32:31': [0.2001211, 0.1932651, 0.2002864], '1': [0.2001211, 0.1932651, 0.2002864]}\n",
            "{'Brawler_1_02_08_2022_00_49.csv': {'Brawler': [[494, 1047, 1453, 9190, 11785, 12378, 14560, 20776, 20776, 378, 2840], [8829, 15548, 18060, 19795, 19863, 20417, 21139, 21762, 27576, 3054, 4660], [10534, 22181, 26814, 30327, 35099, 41009, 46389, 56164, 58369, 7926, 15190], [36723, 46389, 51863, 63547, 76626, 79677, 2328, 3964, 4257, 31775], [77339, 0, 18269, 0, 19783, 0]], 'Mage': [[], [], [], [], []], 'Swordsman': [[], [], [], [], []]}, 'Swordsman_1_02_08_2022_00_49.csv': {'Brawler': [[], [], [], [], []], 'Mage': [[], [], [], [], []], 'Swordsman': [[494, 1453, 2421, 6915, 9918, 11785, 13652, 2252, 9840, 4520], [1220, 1220, 4259, 12314, 13652, 14215, 15112, 21430, 21430, 28681, 5763, 480, 6785, 2015, 15286, 10027, 14770], [14560, 14972, 20417, 22201, 25807, 28365, 28831, 35099, 37490, 42255, 66534, 13000, 13281, 13161], [29660, 34003, 37490, 41312, 48011, 49147, 50170, 64643, 68249, 77007, 2705, 23530], [7502, 0, 22249, 0, 22623, 0, 24071, 0, 24443, 0, 28730, 0, 29792, 0, 31056, 0, 33928, 0]]}, 'Mage_1_02_08_2022_00_49.csv': {'Brawler': [[], [], [], [], []], 'Mage': [[1047, 2421, 4761, 9582, 12314, 12378, 13874, 14215, 15548, 29136, 5459, 3059, 1257, 5753, 9741], [4761, 9582, 13874, 19863, 20048, 21762, 27576, 32346, 34697, 39390, 1824, 3822, 8304, 6158, 15069, 3981, 9700], [14972, 22181, 29438, 34003, 36526, 38597, 42255, 46185, 51452, 59778, 7144, 6109, 14623, 9981, 20300, 26389], [26814, 37148, 49177, 61420, 70537, 72693, 72862, 73056, 76508, 80176, 29185], [75654, 0, 11982, 0, 13945, 0, 15614, 0, 17416, 0, 27051, 0, 28016, 0, 35498, 0]], 'Swordsman': [[], [], [], [], []]}}\n"
          ]
        }
      ],
      "source": [
        "print(configuration_data)\n",
        "print(game_play_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "25e73506",
      "metadata": {
        "id": "25e73506",
        "outputId": "d0cd7d1e-d84c-47a8-bb09-6be1c8bd1589",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]\n"
          ]
        }
      ],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "VOE7PnkEA88C",
      "metadata": {
        "id": "VOE7PnkEA88C"
      },
      "outputs": [],
      "source": [
        "reviews = { \"02/08/2022 00:32:31\": [0, 0, 1], \"Test2\": [0, 0, 1] }\n",
        "from sklearn.model_selection import train_test_split\n",
        "y = list(reviews.keys())\n",
        "labels = []\n",
        "labeled_config = []\n",
        "for key in y:\n",
        "  if key in configuration_data:\n",
        "    data = configuration_data[key]\n",
        "    labeled_config.append(data)\n",
        "    labels.append(reviews[key])\n",
        "\n",
        "unlabeled_data = []\n",
        "for key in configuration_data:\n",
        "  if key not in y:\n",
        "    data = configuration_data[key]\n",
        "    unlabeled_data.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "NB5FzG02EcO0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB5FzG02EcO0",
        "outputId": "65b2a8e2-8f37-4ae7-97b5-a71dc078a93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.2001211, 0.1932651, 0.2002864]]\n",
            "02/08/2022 00:32:31\n",
            "[[0, 0, 1]]\n",
            "[[0.2001211, 0.1932651, 0.2002864]]\n"
          ]
        }
      ],
      "source": [
        "print(labeled_config)\n",
        "print(config[0])\n",
        "config = [config, config]\n",
        "print(labels)\n",
        "labels.append(labels[0])\n",
        "print(unlabeled_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_data = [labeled_config[0], labeled_config[0]]\n",
        "print(labels)"
      ],
      "metadata": {
        "id": "l9ZCBJPL_vqq",
        "outputId": "e2ac29b9-11a9-433c-db38-d1aa847e27d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "l9ZCBJPL_vqq",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 1], [0, 0, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bN88s0qkDDAr",
      "metadata": {
        "id": "bN88s0qkDDAr"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels, val_data, val_labels = train_test_split(label_data, labels, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "HXgPXUNsGVg5",
      "metadata": {
        "id": "HXgPXUNsGVg5"
      },
      "outputs": [],
      "source": [
        "# Helper function for merging new history objects with older ones\n",
        "def append_history(losses, val_losses, accuracy, val_accuracy, history):\n",
        "    losses = losses + history.history[\"loss\"]\n",
        "    val_losses = val_losses + history.history[\"val_loss\"]\n",
        "    accuracy = accuracy + history.history[\"categorical_accuracy\"]\n",
        "    val_accuracy = val_accuracy + history.history[\"val_categorical_accuracy\"]\n",
        "    return losses, val_losses, accuracy, val_accuracy\n",
        "\n",
        "\n",
        "# Plotter function\n",
        "def plot_history(losses, val_losses, accuracies, val_accuracies):\n",
        "    plt.plot(losses)\n",
        "    plt.plot(val_losses)\n",
        "    plt.legend([\"train_loss\", \"val_loss\"])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(accuracies)\n",
        "    plt.plot(val_accuracies)\n",
        "    plt.legend([\"train_accuracy\", \"val_accuracy\"])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0wWG257MASxZ"
      },
      "id": "0wWG257MASxZ",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "88129aa5",
      "metadata": {
        "id": "88129aa5"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "  x = Input(shape=(3,), name=\"Game Play Data\")\n",
        "\n",
        "  g = Dense(500, activation='relu')(x)\n",
        "  g = Dense(100, activation='relu')(g)\n",
        "  g = Dense(50, activation='relu')(g)\n",
        "  g = Dense(3, activation='softmax')(g)\n",
        "  model = Model(inputs=x, outputs=g)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYh7cG6Q3wL",
        "outputId": "1357c6a5-8426-42d6-a071-dd985db53773"
      },
      "id": "FRYh7cG6Q3wL",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['02/08/2022 00:32:31', 0.2001211, 0.1932651, 0.2002864]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "PrQGne8ovciZ",
      "metadata": {
        "id": "PrQGne8ovciZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86eebd91-9057-4255-f405-d648fa5543e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting to train with 1 samples\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 1: val_loss improved from inf to 1.05867, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0587 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 2: val_loss improved from 1.05867 to 1.05525, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0552 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 3: val_loss improved from 1.05525 to 1.04966, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6522 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0497 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6523 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 4: val_loss improved from 1.04966 to 1.04413, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6523 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0441 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6523 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 5: val_loss improved from 1.04413 to 1.04046, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.6523 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0405 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6524 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 6: val_loss improved from 1.04046 to 1.03671, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6524 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0367 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6524 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 7: val_loss improved from 1.03671 to 1.03349, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6524 - categorical_accuracy: 1.0000 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0335 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6525 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 8: val_loss improved from 1.03349 to 1.03056, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.6525 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0306 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6525 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 9: val_loss improved from 1.03056 to 1.02681, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.6525 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0268 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6526 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 10: val_loss improved from 1.02681 to 1.02396, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6526 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0240 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6527 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 11: val_loss improved from 1.02396 to 1.02061, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6527 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0206 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6528 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 12: val_loss improved from 1.02061 to 1.01685, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6528 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0169 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6529 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 13: val_loss improved from 1.01685 to 1.01316, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6529 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0132 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6530 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 14: val_loss improved from 1.01316 to 1.01055, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.6530 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0106 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6532 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 15: val_loss improved from 1.01055 to 1.00826, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6532 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0083 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6534 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 16: val_loss improved from 1.00826 to 1.00824, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6534 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0082 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6536 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 17: val_loss improved from 1.00824 to 1.00807, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6536 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0081 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6539 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 18: val_loss did not improve from 1.00807\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6539 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0084 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6543 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 19: val_loss did not improve from 1.00807\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6543 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0082 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.6546 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00\n",
            "Epoch 20: val_loss improved from 1.00807 to 1.00735, saving model to AL_Model.h5\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6546 - categorical_accuracy: 0.0000e+00 - false_negatives_2: 3.0000 - false_positives_2: 0.0000e+00 - val_loss: 1.0074 - val_categorical_accuracy: 1.0000 - val_false_negatives_2: 1.0000 - val_false_positives_2: 0.0000e+00\n"
          ]
        }
      ],
      "source": [
        "num_iterations=3\n",
        "sampling_size=5000\n",
        "# inspired from this https://keras.io/examples/nlp/active_learning_review_classification/\n",
        "model = make_model()\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\n",
        "          keras.metrics.CategoricalAccuracy(),\n",
        "          keras.metrics.FalseNegatives(),\n",
        "          keras.metrics.FalsePositives(),\n",
        "      ],)\n",
        "losses, val_losses, accuracies, val_accuracies = [], [], [], []\n",
        "\n",
        "# Defining checkpoints.\n",
        "# The checkpoint callback is reused throughout the training since it only saves the best overall model.\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"AL_Model.h5\", save_best_only=True, verbose=1\n",
        ")\n",
        "# Here, patience is set to 4. This can be set higher if desired.\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=4, verbose=1)\n",
        "\n",
        "print(f\"Starting to train with {len(train_data)} samples\")\n",
        "# Initial fit with a small subset of the training set\n",
        "history = model.fit(\n",
        "    x=train_data,\n",
        "    y=train_labels,\n",
        "    epochs=20,\n",
        "    validation_data=(val_data, val_labels),\n",
        "    callbacks=[checkpoint, early_stopping],\n",
        ")\n",
        "\n",
        "# Appending history\n",
        "losses, val_losses, accuracies, val_accuracies = append_history(\n",
        "    losses, val_losses, accuracies, val_accuracies, history\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "used = []\n",
        "for iteration in range(num_iterations):\n",
        "  # Getting predictions from previously trained model\n",
        "  predictions = model.predict(unlabeled_data)\n",
        "  length = min(len(predictions), 10)\n",
        "  minValue = 1\n",
        "  for x in range(length):\n",
        "    if x not in used:\n",
        "      predict = predictions[x]\n",
        "      maxValue = max(predict)\n",
        "      if maxValue < minValue:\n",
        "        minValue = maxValue\n",
        "  if minValue != 1:\n",
        "    used.append()\n",
        "\n",
        "  continue\n",
        "  \n",
        "\n",
        "  # We recompile the model to reset the optimizer states and retrain the model\n",
        "  model.compile(\n",
        "      loss=\"categorical_crossentropy\",\n",
        "      optimizer=\"rmsprop\",\n",
        "      metrics=[\n",
        "          keras.metrics.CategoricalAccuracy(),\n",
        "          keras.metrics.FalseNegatives(),\n",
        "          keras.metrics.FalsePositives(),\n",
        "      ],\n",
        "  )\n",
        "  history = model.fit(\n",
        "      x=train_data,\n",
        "      y=train_labels,\n",
        "      validation_data=(val_data, val_labels),\n",
        "      epochs=20,\n",
        "      callbacks=[\n",
        "          checkpoint,\n",
        "          keras.callbacks.EarlyStopping(patience=4, verbose=1),\n",
        "      ],\n",
        "  )\n",
        "\n",
        "  # Appending the history\n",
        "  losses, val_losses, accuracies, val_accuracies = append_history(\n",
        "      losses, val_losses, accuracies, val_accuracies, history\n",
        "  )\n",
        "\n",
        "  # Loading the best model from this training loop\n",
        "  model = keras.models.load_model(\"AL_Model.h5\")"
      ],
      "metadata": {
        "id": "acUFA1ffAtq9"
      },
      "id": "acUFA1ffAtq9",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the overall history and evaluating the final model\n",
        "  plot_history(losses, val_losses, accuracies, val_accuracies)\n",
        "  print(\"-\" * 100)\n",
        "  print(\n",
        "      \"Test set evaluation: \",\n",
        "      model.evaluate(test_dataset, verbose=0, return_dict=True),\n",
        "  )\n",
        "  print(\"-\" * 100)"
      ],
      "metadata": {
        "id": "2vA_5vlSRXL_"
      },
      "id": "2vA_5vlSRXL_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e467ce8",
      "metadata": {
        "id": "4e467ce8"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "active_learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}